{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Mem2Seq import Mem2Seq\n",
    "from utils.preprocess import preprocess\n",
    "\n",
    "vocab_path = './parameters/bpe.vocab'\n",
    "codes_path = './parameters/bpe.code'\n",
    "\n",
    "train_datasets = ['./datasets/train_self_revised_no_cands.txt',\n",
    "                  './datasets/train_self_original_no_cands.txt']\n",
    "valid_datasets = ['./datasets/valid_self_revised_no_cands.txt']\n",
    "test_datasets = ['./datasets/valid_self_original_no_cands.txt']\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "vocab, train_loader, valid_loader, test_loader, max_r = preprocess(vocab_path, codes_path, train_datasets, valid_datasets, test_datasets, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<i>i like to get involved in politics . i 'm looking to start a business . i 've a brand new chevrolet . i enjoy hanging out with friends and family . i 'm a big sports fan . </i><t1>_ _ silence _ _ </t1><t2>good afternoon ! how are you ? </t2><t1>i 'm really good . . . . how are you today </t1><t2>i 'm doing really well , thanks for asking . my family and i just bought a new chevrolet . </t2><t1>oh wow that must be really nice . . . . . . do you by any chance believe in dragons </t1><t2>sure ! if i could capture one , it would be great business ! </t2><t1>me too and i assume riding one would be like driving a chevrolet </t1><t2>ha ! yes ! could you imagine how many friends could ride too ? </t2><t1>i know . . . . . do you work a job ? </t1><t2>yes , i 'm involved in politics . </t2><t1>oh wow i bet you have to talk to people all the time that would be hard </t1><t2>yes , but i spend a lot of time with family and friends so , that helps . </t2><t1>oh that is nice family is important </t1><t2>yes , we enjoy going to sporting events together . how about yourself ? </t2><t1>i really like dungeons and dragons </t1>$$$$\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = iter(train_loader).next()\n",
    "vocab.ids2string(data[0][:, 0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "hdd = 300\n",
    "layer = 4\n",
    "dr = 0.2\n",
    "path = None\n",
    "model = Mem2Seq(hidden_size=hdd, max_r=max_r, vocab=vocab, path=path,\n",
    "                lr=lr, n_layers=layer, dropout=dr, unk_mask=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:7.85, VL:4.79, PL:3.07: 100%|██████████| 1118/1118 [08:24<00:00,  2.56it/s]\n",
      "  0%|          | 0/1118 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<samples>\n",
      "['<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
      "['i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>', 'i</w>']\n",
      "['do</w>', 'do</w>', 'am</w>', 'do</w>', 'do</w>', 'am</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>', 'am</w>', 'am</w>', 'do</w>', 'do</w>', 'am</w>', 'am</w>', 'am</w>', 'do</w>', 'am</w>', 'do</w>', 'am</w>', 'am</w>', 'do</w>', 'do</w>', 'do</w>', 'do</w>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L:7.51, VL:4.52, PL:2.99:  16%|█▌        | 180/1118 [01:24<07:22,  2.12it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d071217469e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         model.train_batch(data[0], data[1], data[2], data[3], data[4], data[5],\n\u001b[0;32m---> 11\u001b[0;31m                         len(data[1]), 10.0, 0.5, i==0) \n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mem2seq-persona/Mem2Seq.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, input_batches, input_lengths, target_batches, target_lengths, target_index, target_gate, batch_size, clip, teacher_forcing_ratio, reset)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_Vocab\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_Ptr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Clip gradient norms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dev = iter(valid_loader).next()\n",
    "for epoch in range(10):\n",
    "    logging.info(\"Epoch:{}\".format(epoch))  \n",
    "    # Run the train function\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, data in pbar: \n",
    "        model.train_batch(data[0], data[1], data[2], data[3], data[4], data[5],\n",
    "                        len(data[1]), 10.0, 0.5, i==0) \n",
    "        pbar.set_description(model.print_loss())\n",
    "        \n",
    "    words = model.evaluate_batch(len(data_dev[1]), data_dev[0], data_dev[1], data_dev[2],\n",
    "                                        data_dev[3], data_dev[4], data_dev[5], data_dev[6])\n",
    "    print('<samples>')\n",
    "    print(words[0])\n",
    "    print(words[1])\n",
    "    print(words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<i>'],\n",
       " ['i</w>'],\n",
       " ['have</w>'],\n",
       " ['special</w>'],\n",
       " ['di'],\n",
       " ['etary</w>'],\n",
       " ['restrictions</w>'],\n",
       " ['.</w>'],\n",
       " ['i</w>'],\n",
       " [\"'ve</w>\"],\n",
       " ['been</w>'],\n",
       " ['know</w>'],\n",
       " ['to</w>'],\n",
       " ['finish</w>'],\n",
       " ['almost</w>'],\n",
       " ['two</w>'],\n",
       " ['dozen</w>'],\n",
       " ['novels</w>'],\n",
       " ['in</w>'],\n",
       " ['a</w>'],\n",
       " ['twelve</w>'],\n",
       " ['month</w>'],\n",
       " ['period</w>'],\n",
       " ['.</w>'],\n",
       " ['my</w>'],\n",
       " ['mom</w>'],\n",
       " ['and</w>'],\n",
       " ['dad</w>'],\n",
       " ['divorced</w>'],\n",
       " ['when</w>'],\n",
       " ['i</w>'],\n",
       " ['was</w>'],\n",
       " ['young</w>'],\n",
       " ['.</w>'],\n",
       " ['</i>'],\n",
       " ['<t1>'],\n",
       " ['hello</w>'],\n",
       " ['what</w>'],\n",
       " ['are</w>'],\n",
       " ['doing</w>'],\n",
       " ['today</w>'],\n",
       " ['?</w>'],\n",
       " ['</t1>'],\n",
       " ['<t2>'],\n",
       " ['i</w>'],\n",
       " ['am</w>'],\n",
       " ['good</w>'],\n",
       " [',</w>'],\n",
       " ['i</w>'],\n",
       " ['just</w>'],\n",
       " ['got</w>'],\n",
       " ['off</w>'],\n",
       " ['work</w>'],\n",
       " ['and</w>'],\n",
       " ['tired</w>'],\n",
       " [',</w>'],\n",
       " ['i</w>'],\n",
       " ['have</w>'],\n",
       " ['two</w>'],\n",
       " ['jobs</w>'],\n",
       " ['.</w>'],\n",
       " ['</t2>'],\n",
       " ['<t1>'],\n",
       " ['i</w>'],\n",
       " ['just</w>'],\n",
       " ['got</w>'],\n",
       " ['done</w>'],\n",
       " ['watching</w>'],\n",
       " ['a</w>'],\n",
       " ['horror</w>'],\n",
       " ['movie</w>'],\n",
       " ['</t1>'],\n",
       " ['<t2>'],\n",
       " ['i</w>'],\n",
       " ['rather</w>'],\n",
       " ['read</w>'],\n",
       " [',</w>'],\n",
       " ['i</w>'],\n",
       " [\"'ve</w>\"],\n",
       " ['read</w>'],\n",
       " ['about</w>'],\n",
       " ['20</w>'],\n",
       " ['books</w>'],\n",
       " ['this</w>'],\n",
       " ['year</w>'],\n",
       " ['.</w>'],\n",
       " ['</t2>'],\n",
       " ['<t1>'],\n",
       " ['wow</w>'],\n",
       " ['!</w>'],\n",
       " ['i</w>'],\n",
       " ['do</w>'],\n",
       " ['love</w>'],\n",
       " ['a</w>'],\n",
       " ['good</w>'],\n",
       " ['horror</w>'],\n",
       " ['movie</w>'],\n",
       " ['.</w>'],\n",
       " ['loving</w>'],\n",
       " ['this</w>'],\n",
       " ['cooler</w>'],\n",
       " ['weather</w>'],\n",
       " ['</t1>'],\n",
       " ['$$$$']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev = iter(valid_loader).next()\n",
    "data_dev[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = model.encoder(data_dev[0]).unsqueeze(0)\n",
    "model.decoder.load_memory(data_dev[0].transpose(0, 1))\n",
    "\n",
    "# Prepare input and output variables\n",
    "decoder_input = torch.tensor([model.vocab.bos_id] * len(data_dev[1]), dtype=torch.long, device=model.device)\n",
    "\n",
    "decoded_words = []\n",
    "all_decoder_outputs_vocab = torch.zeros(model.max_r, len(data_dev[1]), model.output_size, device=model.device)\n",
    "all_decoder_outputs_ptr = torch.zeros(model.max_r, len(data_dev[1]), data_dev[0].size(0), device=model.device)\n",
    "#all_decoder_outputs_gate = torch.zeros(self.max_r, batch_size, device=self.device)\n",
    "\n",
    "p = []\n",
    "for elm in data_dev[6]:\n",
    "    elm_temp = [ word_triple[0] for word_triple in elm ]\n",
    "    p.append(elm_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<i>', 'i</w>', 'have</w>', 'special</w>', 'di', 'etary</w>', 'restrictions</w>', '.</w>', 'my</w>', 'mom</w>', 'and</w>', 'dad</w>', 'divorced</w>', 'when</w>', 'i</w>', 'was</w>', 'young</w>', '.</w>', '</i>', '<t1>', 'hello</w>', 'what</w>', 'are</w>', 'doing</w>', 'today</w>', '?</w>', '</t1>', '<t2>', 'i</w>', 'am</w>', 'good</w>', ',</w>', 'i</w>', 'just</w>', 'got</w>', 'off</w>', 'work</w>', 'and</w>', 'tired</w>', ',</w>', 'i</w>', 'have</w>', 'two</w>', 'jobs</w>', '.</w>', '</t2>', '<t1>', 'i</w>', 'just</w>', 'got</w>', 'done</w>', 'watching</w>', 'a</w>', 'horror</w>', 'movie</w>', '</t1>', '<t2>', 'i</w>', 'rather</w>', 'read</w>', ',</w>', 'i</w>', \"'ve</w>\", 'read</w>', 'about</w>', '20</w>', 'books</w>', 'this</w>', 'year</w>', '.</w>', '</t2>', '<t1>', 'wow</w>', '!</w>', 'i</w>', 'do</w>', 'love</w>', 'a</w>', 'good</w>', 'horror</w>', 'movie</w>', '.</w>', 'loving</w>', 'this</w>', 'cooler</w>', 'weather</w>', '</t1>', '<t2>', 'but</w>', 'a</w>', 'good</w>', 'movie</w>', 'is</w>', 'always</w>', 'good</w>', '.</w>', '</t2>', '<t1>', 'yes</w>', '!</w>', 'my</w>', 'son</w>', 'is</w>', 'in</w>', 'junior</w>', 'high</w>', 'and</w>', 'i</w>', 'just</w>', 'started</w>', 'letting</w>', 'him</w>', 'watch</w>', 'them</w>', 'too</w>', '</t1>', '<t2>', 'i</w>', 'work</w>', 'in</w>', 'the</w>', 'movies</w>', 'as</w>', 'well</w>', '.</w>', '</t2>', '<t1>', 'neat</w>', '!</w>', '!</w>', 'i</w>', 'used</w>', 'to</w>', 'work</w>', 'in</w>', 'the</w>', 'human</w>', 'services</w>', 'field</w>', '</t1>', '<t2>', 'yes</w>', 'it</w>', 'is</w>', 'neat</w>', ',</w>', 'i</w>', 'stunt</w>', 'double</w>', ',</w>', 'it</w>', 'is</w>', 'so</w>', 'much</w>', 'fun</w>', 'and</w>', 'hard</w>', 'work</w>', '.</w>', '</t2>', '<t1>', 'yes</w>', 'i</w>', 'bet</w>', 'you</w>', 'can</w>', 'get</w>', 'hurt</w>', '.</w>', 'my</w>', 'wife</w>', 'works</w>', 'and</w>', 'i</w>', 'stay</w>', 'at</w>', 'home</w>', '</t1>', '$$$$', '$$$$']\n"
     ]
    }
   ],
   "source": [
    "print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"not not good not not a not n't n't n't not not n't not not not a a not not a a a not a not good a not not not not \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.vocab import CustomVocab\n",
    "\n",
    "''.join(words[3]).replace(CustomVocab.we, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
